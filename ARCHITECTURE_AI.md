# Архитектура AI-ассистента TG Hub

## Цель

Единый AI-ассистент: человекоподобный, персонализированный, проактивный. Handlers только передают команды и контекст в AI Service; доступ к задачам, людям и напоминаниям — только через AI (на стороне API).

---

## Поток данных

```
Пользователь (Telegram)
    → Handler (только user_id + message)
    → AI Service.generate_response(user_id, message)
    → API /api/chat (контекст: задачи, люди, знания, финансы, история чата)
    → LLM
    → ответ пользователю
```

- **Бот и handlers не знают SQL.** Данные (tasks, people, reminders) подставляются в контекст на стороне API.
- **TaskService, PeopleService, ReminderService** в смысле «данные для ответа» доступны только внутри API при формировании ответа. Бот вызывает только `generate_response(user_id, message)`.

---

## Компоненты

### 1. AI Service (бот)

- **Интерфейс:** `generate_response(user_id, message) -> str`
- **Реализация:** `ApiAiService` — POST в `/api/chat` с `X-User-Id` и телом `{ "message": "..." }`.
- Контекст диалога и состояние задач хранятся в API (таблица `chat_history` и данные по `user_id`). Опционально бот может хранить свой кэш в `DialogContextManager` (для будущей проактивности).

### 2. API /api/chat

- Собирает контекст: задачи, контакты, знания, финансы, лимиты, последние операции.
- Подставляет дату/время, формирует системный промпт.
- Загружает историю чата из репозитория, добавляет новый поворот, вызывает LLM (OpenRouter и др.).
- Сохраняет ответ в `chat_history`.
- Обрабатывает прямые команды («новый диалог», «забудь про X», создание задачи/контакта/расхода и т.д.) через `parse_user_command` / `execute_ai_action`.

### 3. Контекст и память

- **История диалога:** в API, репозиторий `chat_history` (чтение/запись только в API).
- **Бот:** `DialogContextManager` — опциональный кэш по `user_id` (например, last_topic, last_intent) для будущих проактивных подсказок. Сейчас основная память — в API.

### 4. Проактивность

- **В чате:** системный промпт предписывает при встречах/созвонах/звонках «сегодня или скоро» предлагать подготовиться или напомнить проверить.
- **В напоминаниях:** при отправке напоминания по задаче (RemindersService), если в названии есть «встреча», «созвон», «звонок» — к тексту добавляется «Подготовиться?».

---

## Примеры сценариев

| Запрос пользователя | Поведение |
|---------------------|-----------|
| «Что у меня сегодня?» | API собирает задачи/контекст по user_id, LLM формирует один понятный ответ. |
| «Напомни про встречу с Андреем» | Пользователь может создать задачу с напоминанием через команду в чат (API выполняет действие); AI подсказывает формулировки. |
| Напоминание «Встреча в 15:00» | RemindersService шлёт напоминание с подписью «Подготовиться?». |
| «Очисти диалог» | API очищает историю по user_id и возвращает подтверждение. |

---

## Ограничения архитектуры

- **Handlers:** только передача `user_id` и `message` в AI Service, без бизнес-логики и без прямого доступа к БД/сервисам.
- **AI Service (бот):** единый вход — `generate_response(user_id, message)`; не содержит SQL, не вызывает репозитории напрямую.
- **Доступ к задачам/людям/напоминаниям для ответа:** только в API при построении контекста для LLM; бот эти данные не читает.

---

## Расширение

- **Роли (личный, рабочий, клиенты):** можно добавить в профиль пользователя поле `role` или `context_type` и подставлять его в системный промпт в API.
- **Более богатая проактивность:** использовать `DialogContextManager` на боте и/или отдельные воркеры в API, которые по расписанию проверяют «встреча через час» и отправляют подсказки.
- **Другой LLM:** замена в `api/services/ai_client.py`; контракт «сообщения + системный промпт → ответ» сохраняется.
